# FrozenLake Gymnasium Project

A Python project implementing reinforcement learning agents for the Gymnasium FrozenLake environment.

## Overview

FrozenLake is a classic grid-world environment where an agent must navigate across a frozen lake from the starting position to the goal while avoiding holes in the ice. The lake is slippery, so the agent doesn't always move in the intended direction.

**Environment Details:**
- **Grid Size:** 4x4 (default) or 8x8
- **Actions:** 4 discrete actions (Left, Down, Right, Up)
- **States:** 16 positions (4x4 grid)
- **Objective:** Navigate from Start (S) to Goal (G) while avoiding Holes (H)

## Project Structure

```
frozenlake/
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ run.sh                    # ğŸš€ Script de lancement rapide (Linux/Mac)
â”œâ”€â”€ run.bat                   # ğŸš€ Script de lancement rapide (Windows)
â”œâ”€â”€ frozenlake_gui.py         # ğŸ“ Interface graphique interactive (RECOMMANDÃ‰!)
â”œâ”€â”€ frozenlake_qlearning.py   # Q-learning agent implementation
â”œâ”€â”€ frozenlake_random.py      # Random baseline agent
â”œâ”€â”€ frozenlake_visual_demo.py # Visual demo with graphical rendering
â”œâ”€â”€ venv/                     # Virtual environment
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Lancement Rapide (RecommandÃ©!)

### Linux / Mac:
```bash
./run.sh
```

### Windows:
```bash
run.bat
```

Ces scripts vont automatiquement:
- âœ… CrÃ©er le virtual environment (si nÃ©cessaire)
- âœ… Installer les dÃ©pendances
- âœ… Lancer l'interface graphique

**C'est la mÃ©thode la plus simple pour dÃ©marrer!**

## Installation Manuelle

Si vous prÃ©fÃ©rez installer manuellement:

1. **Sur Linux, installer tkinter si nÃ©cessaire:**
```bash
# Ubuntu/Debian
sudo apt-get install python3-tk

# Fedora
sudo dnf install python3-tkinter

# Arch
sudo pacman -S tk
```

2. Create a virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

**Note:** Tkinter est inclus par dÃ©faut avec Python sur Windows et Mac. Sur Linux, il peut nÃ©cessiter une installation systÃ¨me.

## Usage

### ğŸ“ Interface Graphique Interactive (RECOMMANDÃ‰ pour les Ã‰tudiants!)

Lancez l'interface graphique complÃ¨te pour expÃ©rimenter avec les paramÃ¨tres d'apprentissage:

```bash
# Avec le script de lancement (plus simple)
./run.sh  # ou run.bat sur Windows

# Ou manuellement
source venv/bin/activate
python frozenlake_gui.py
```

**FonctionnalitÃ©s de l'Interface:**
- âš™ï¸ **ContrÃ´les des HyperparamÃ¨tres** - Ajustez en temps rÃ©el:
  - Taux d'apprentissage (Î±)
  - Facteur de discount (Î³)
  - DÃ©croissance epsilon
  - Nombre d'Ã©pisodes
  - Taille de carte (4x4 ou 8x8)
  - Glace glissante on/off

- ğŸ“Š **Statistiques en Temps RÃ©el:**
  - Progression de l'entraÃ®nement
  - Taux de rÃ©ussite
  - Epsilon actuel
  - RÃ©compense moyenne
  - Temps Ã©coulÃ©

- ğŸ® **PrÃ©rÃ©glages PrÃªts Ã  l'Emploi:**
  - **DÃ©butant** - Apprentissage rapide sans glace
  - **Rapide** - EntraÃ®nement accÃ©lÃ©rÃ©
  - **Optimal** - Meilleure performance finale

- ğŸ‘ï¸ **DÃ©mo Visuelle IntÃ©grÃ©e** - Regardez l'agent entraÃ®nÃ© jouer

Cette interface est parfaite pour comprendre l'impact de chaque hyperparamÃ¨tre sur l'apprentissage!

### Visual Demo (Command Line)

Watch the agent learn and play with graphical rendering:

```bash
python frozenlake_visual_demo.py
```

This interactive demo offers:
1. **Random Agent** - Watch an agent move randomly (no learning)
2. **Trained Agent** - See a Q-learning agent navigate successfully
3. **Compare Both** - See random vs trained side-by-side
4. **Quick Demo** - Fast 3-episode demonstration

The visual demo shows the grid with:
- **S** (Start) - Blue square where the agent begins
- **F** (Frozen) - White ice tiles (safe to walk on)
- **H** (Hole) - Black holes (game over if you fall in)
- **G** (Goal) - Green target to reach
- **Agent** - Red circle showing current position

### Train Q-Learning Agent

Train an agent using Q-learning algorithm:

```bash
python frozenlake_qlearning.py
```

This will:
- Train the agent for 10,000 episodes
- Print progress every 1,000 episodes
- Evaluate the trained agent over 100 test episodes
- Display final win rate and average reward

### Run Random Agent Baseline

See how a random agent performs:

```bash
python frozenlake_random.py
```

This demonstrates the baseline performance without learning.

## How It Works

### Q-Learning Algorithm

The Q-learning agent learns by:
1. **Exploration vs Exploitation:** Using epsilon-greedy policy to balance exploring new actions and exploiting learned knowledge
2. **Q-Table Updates:** Learning optimal action values using the Q-learning formula:
   ```
   Q(s,a) â† Q(s,a) + Î±[r + Î³Â·max(Q(s',a')) - Q(s,a)]
   ```
   where:
   - Î± (alpha) = learning rate
   - Î³ (gamma) = discount factor
   - r = reward
   - s = current state
   - a = action taken
   - s' = next state

3. **Epsilon Decay:** Gradually reducing exploration as the agent learns

### Hyperparameters

Default parameters in `frozenlake_qlearning.py`:
- **Learning Rate (Î±):** 0.1
- **Discount Factor (Î³):** 0.99
- **Initial Epsilon:** 1.0 (100% exploration)
- **Epsilon Decay:** 0.995
- **Minimum Epsilon:** 0.01
- **Training Episodes:** 10,000

## Customization

### Modify Hyperparameters

Edit the agent initialization in `frozenlake_qlearning.py`:

```python
agent = QLearningAgent(
    env=env,
    learning_rate=0.1,      # Adjust learning rate
    discount_factor=0.95,   # Adjust discount factor
    epsilon=1.0,            # Initial exploration rate
    epsilon_decay=0.99,     # Adjust decay rate
    epsilon_min=0.01        # Minimum exploration
)
```

### Use 8x8 Map

Change the environment creation to use a larger map:

```python
env = gym.make("FrozenLake-v1", map_name="8x8", is_slippery=True)
```

### Disable Slippery Ice

For deterministic movement:

```python
env = gym.make("FrozenLake-v1", is_slippery=False)
```

## Expected Results

- **Random Agent:** ~1-2% win rate
- **Q-Learning Agent:** ~70-80% win rate (4x4 slippery map)

The Q-learning agent significantly outperforms random actions by learning optimal paths.

## Resources

- [Gymnasium FrozenLake Documentation](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)
- [Q-Learning Algorithm](https://en.wikipedia.org/wiki/Q-learning)
- [Gymnasium Documentation](https://gymnasium.farama.org/)

## License

This project is open source and available for educational purposes.
